{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_calling_random(df, silence=False, homology=False, acid_labile=False, methyl=False, base_only=False):\n",
    "    df = df.sort_index()\n",
    "    mass_x = np.array(df.Mass)\n",
    "    mass_y = np.array(df.Mass)\n",
    "    if acid_labile:\n",
    "        mass_x = np.array(df[df.isAD == False].Mass)\n",
    "        mass_y = np.array(df[df.isAD == True].Mass)\n",
    "    if not silence:\n",
    "        print(\"mass_x {} mass_y {}\".format(mass_x.shape, mass_y.shape))\n",
    "\n",
    "#     base_dict = {'C': 305.0413, 'A': 329.0525, 'G': 345.0474, 'U': 306.0253, 'g': 359.0631, 'D': 308.041, 'c': 319.0569, 'u': 320.041, 'G^': 373.0787, 'a': 343.0682, 'y': 212.0086, 'Y': 570.1475, 'P': 557.2251, 'x': 688.1156, 'z': 625.0844, 'I': 330.03654, 'O': 344.052}\n",
    "    base_dict = {'C': 305.0413, 'A': 329.0525, 'G': 345.0474, 'U': 306.0253, \n",
    "                 'mG': 359.0631, 'D': 308.041, 'mC': 319.0569, \n",
    "                 'mU': 320.041, 'mA': 343.0682, 'm22C': 333.0625,\n",
    "                'mcm5U': 378.0464, 'Î¨*': 557.2251} #, 'y': 212.0086, 'mnm5s2U': 365.04466, 'X': 449.08299, 's4U': 322.00246, 'ms2io6A': 459.09776\n",
    "#     base_dict = {'g': 359.0631, 'u': 320.041, 'mnm5s2U': 365.04466, 'X': 449.08299, 's4U': 322.00246, 'ms2io6A': 459.09776} #387.1273+61.9557\n",
    "    if homology:\n",
    "#         base_dict = {'Me': 14.0106} \n",
    "#         base_dict = {'C (305.04)': 305.0413, 'A (329.05)': 329.0525, 'endA (249.09)': 249.0862, 'endC (225.08)': 225.075, 'Me (14.01)': 14.0106, '2Me (14.01)': 28.0212} #, 'Udiff': 43\n",
    "        base_dict = {'C': 305.0413, 'A': 329.0525, 'Ai': 249.0862, 'Ci': 225.075, 'Ox': 16.0, 'Methyl': 14.0106, '2Methyl': 28.0212} #, 'Udiff': 43\n",
    "#         base_dict = {'Y (358.16)': 358.1599, 'C (305.04)': 305.0413, 'A (329.05)': 329.0525, 'endA (249.09)': 249.0862, 'endC (225.08)': 225.075, 'Methyl (14.01)': 14.0106}\n",
    "    if acid_labile:\n",
    "#         base_dict = {'Y': 358.1599, 'm6t6A': 276.09568, 'Gr(p)': 345.04602, 'cnm5U': 133.0262, 'I': 118.02654, 'g6A': 218.05381, 'o2yW': 390.12737, 'ms2t6A': 308.06775, 'acp3U/cmnm5Um': 195.06298, 'mcmo5U': 182.03135}\n",
    "        base_dict = {'Y': 358.1599}\n",
    "    if methyl:\n",
    "        base_dict = {'Me': 14.0106} #, '2Me': 28.0212\n",
    "    if base_only:\n",
    "        base_dict = {'C': 305.0413, 'A': 329.0525, 'G': 345.0474, 'U': 306.0253}\n",
    "    pairs = list()\n",
    "    idxs = list()\n",
    "    PPM = 10\n",
    "    for k in base_dict.keys():\n",
    "        base_mass = base_dict.get(k)\n",
    "        ppm_matrix = np.abs((mass_x[:, np.newaxis] - mass_y - base_mass) * 1E6 / (mass_y + base_mass))\n",
    "        ppm_df = pd.DataFrame(ppm_matrix)\n",
    "        crosstalk = ppm_df[ppm_df < PPM]\n",
    "        idx_pairs = list(crosstalk[crosstalk.notnull()].stack().index)\n",
    "        if idx_pairs:\n",
    "            idx_pairs = [(*pair, k) for pair in idx_pairs] # append base name into idx_pairs\n",
    "            pairs.extend(idx_pairs)\n",
    "        df3_idxs = [pair[0] for pair in idx_pairs]\n",
    "        df5_idxs = [pair[1] for pair in idx_pairs]\n",
    "        df3_idxs = list(set(df3_idxs))\n",
    "        df5_idxs = list(set(df5_idxs))\n",
    "#         if not silence:\n",
    "#             print(\"df3_idxs {} df5_idxs {}\".format(len(df3_idxs), len(df5_idxs)))\n",
    "        if df3_idxs:\n",
    "            idxs.extend(df3_idxs)\n",
    "        if df5_idxs:\n",
    "            idxs.extend(df5_idxs)\n",
    "    \n",
    "    mass_pairs = [(df.Mass.iloc[p[0]], df.Mass.iloc[p[1]], p[2]) for p in pairs]\n",
    "    if acid_labile:\n",
    "        mass_pairs = [(df[df.isAD == False].Mass.iloc[p[0]], df[df.isAD == True].Mass.iloc[p[1]], p[2]) for p in pairs]\n",
    "    mass_pairs = [mp for mp in mass_pairs if mp[0] != mp[1]] # remove item which contains duplicated values\n",
    "    idxs = list(set(idxs))\n",
    "#     plt.figure(figsize=(16, 12))\n",
    "    df_base_calling = df.iloc[idxs]\n",
    "    if acid_labile:\n",
    "        masses = [pair[0] for pair in mass_pairs]\n",
    "        masses_1 = [pair[1] for pair in mass_pairs]\n",
    "        masses.extend(masses_1)\n",
    "        masses = list(set(masses))\n",
    "        df_base_calling = df[df.Mass.isin(masses)]\n",
    "    return df_base_calling, mass_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basecalling_groups(df, homology=False):\n",
    "    \"\"\" given ~25k area dots, doing homology search\n",
    "        return a list of group, each group represents a tRNA specy and its isoforms \n",
    "    \"\"\"\n",
    "    def create_graph(bcr):\n",
    "        G = nx.Graph()\n",
    "        for x in bcr[1]:\n",
    "            G.add_edge(x[0], x[1], name=x[2])\n",
    "\n",
    "        cc = list(nx.connected_components(G))\n",
    "        subgraphs = [G.subgraph(x) for x in cc]\n",
    "        subgraphs.sort(key=len, reverse=True)\n",
    "        return subgraphs\n",
    "    def create_graph3(bcr):\n",
    "        G = nx.Graph()\n",
    "        for x in bcr[1]:\n",
    "            G.add_edge(x[0], x[1], name=x[2])\n",
    "\n",
    "        cc = list(nx.connected_components(G))\n",
    "        subgraphs = [G.subgraph(x) for x in cc]\n",
    "        subgraphs.sort(key=len, reverse=True)\n",
    "        subgraphs.sort(lambda subgraph: \n",
    "                       len([node for node in subgraph if node]), \n",
    "                       reverse=True)\n",
    "        return subgraphs\n",
    "    def create_graph2(bcr):\n",
    "        G = nx.DiGraph()\n",
    "        for x in bcr[1]:\n",
    "            small = min(x[:2])\n",
    "            big = max(x[:2])\n",
    "            G.add_edge(small, big, name=x[2])\n",
    "\n",
    "        cc = list(nx.connected_components(G))\n",
    "        subgraphs = [G.subgraph(x) for x in cc]\n",
    "#         subgraphs.sort(key=len, reverse=True)\n",
    "        subgraphs.sort(lambda subgraph: \n",
    "                       len([node for node in subgraph if node.in_degree>0 and node.out_degree>0]), \n",
    "                       reverse=True)\n",
    "        return subgraphs\n",
    "    \n",
    "    bcr = base_calling_random(df, homology=homology)\n",
    "    subgraphs = create_graph3(bcr)\n",
    "    subgraphs_edges = [ [(x[0], x[1], x[2].get('name')) for x in sg.edges(data=True)] for sg in subgraphs]\n",
    "    subgraphs_edges = [sorted(sg_edges, key=lambda x: x[0]) for sg_edges in subgraphs_edges]\n",
    "    subgraphs_nodes = [list(sg.nodes) for sg in subgraphs]\n",
    "    \n",
    "    node_edge_pairs = list()\n",
    "    for group in range(len(subgraphs)):\n",
    "        df_nodes = df[df.Mass.isin(subgraphs_nodes[group])]\n",
    "        edges = subgraphs_edges[group]\n",
    "        node_edge_pairs.append((df_nodes, edges))\n",
    "    \n",
    "    return node_edge_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zone_selection(df, on_selection=None, on_click=None):\n",
    "    import plotly.graph_objects as go\n",
    "    df_draw = df\n",
    "    x = df_draw.Mass\n",
    "    y = df_draw.RT\n",
    "    fig = go.Scatter(x=x, y=y, mode='markers')\n",
    "    f = go.FigureWidget(fig)\n",
    "#     f.update_layout(autosize=False, width=1024, height=700, paper_bgcolor=\"LightSteelBlue\",\n",
    "#         margin=dict(\n",
    "#             l=20,\n",
    "#             r=20,\n",
    "#             b=20,\n",
    "#             t=20,\n",
    "#             pad=4\n",
    "#         ))\n",
    "    scatter = f.data[0]\n",
    "    colors = ['#6371f2'] * df.shape[0]\n",
    "    scatter.marker.color = colors\n",
    "    \n",
    "    def onclick_callback(trace, points, selector):\n",
    "        nonlocal scatter\n",
    "        c = list(scatter.marker.color)\n",
    "        for i in points.point_inds:\n",
    "            c[i] = '#87a14a'\n",
    "            with f.batch_update():\n",
    "                scatter.marker.color = c\n",
    "        \n",
    "        on_click(trace, points, selector)\n",
    "        \n",
    "    if on_selection:\n",
    "        scatter.on_selection(on_selection)\n",
    "    if on_click:\n",
    "        scatter.on_click(onclick_callback)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_dfs(df_src, df_dst, ppm=10, shift=0):\n",
    "    \"\"\"Find the subset contains common mass values that exist in both df_src and df_dst.\n",
    "    \n",
    "    :return: The subset of df_dst.\n",
    "    \"\"\"\n",
    "    def _find_mass(df, mass, ppm=10):\n",
    "        if df.empty:\n",
    "            return df\n",
    "        df = df[(df.Mass < mass+1) & (df.Mass > mass-1)]\n",
    "        if df.shape[0] == 0:\n",
    "            return df\n",
    "        \n",
    "        df_ppm = abs(1E6 * (df.Mass - mass)) / mass\n",
    "        mask = df_ppm < ppm\n",
    "        df_found = df[mask].copy()\n",
    "        df_found['PPM'] = df_ppm[mask]\n",
    "        return df_found\n",
    "    \n",
    "    df_src = df_src.copy()\n",
    "    if shift != 0:\n",
    "        df_src.Mass += shift\n",
    "    idxs = list()\n",
    "    for idx, row in df_src.iterrows():\n",
    "        mass = row.Mass\n",
    "        df_res = _find_mass(df_dst, mass, ppm)\n",
    "        if not df_res.empty:\n",
    "            df_src.loc[idx, 'Match'] = True\n",
    "            idxs.extend(list(df_res.index))\n",
    "    \n",
    "    idxs = list(set(idxs))\n",
    "    df_common = df_dst[df_dst.index.isin(idxs)]\n",
    "    return df_common.copy()\n",
    "\n",
    "def peer_dfs(df_src, df_dst, ppm=10, shift=0):\n",
    "    dfm_shift_l = match_dfs(df_dst, df_src, ppm, -1*shift)\n",
    "    dfm_shift_r = match_dfs(df_src, df_dst, ppm, shift)\n",
    "    return dfm_shift_l, dfm_shift_r\n",
    "    \n",
    "def comm_dfs(df_src, df_dst, ppm=10, shift=0):\n",
    "    \"\"\"Find two subsets contains common mass values.\n",
    "    \n",
    "    :return: Subsets from df_src and df_dst respectively.\n",
    "    \"\"\"\n",
    "    dfm_comm_dst = match_dfs(df_src, df_dst, ppm, shift)\n",
    "    dfm_comm_src = match_dfs(df_dst, df_src, ppm, shift)\n",
    "    return dfm_comm_src, dfm_comm_dst\n",
    "\n",
    "def diff_dfs(df_src, df_dst, ppm=10, shift=0):\n",
    "    \"\"\"Find two subsets excluded common mass values.\n",
    "    \n",
    "    :return: Subsets from df_src and df_dst respectively.\n",
    "    \"\"\"\n",
    "    df_comm_src, df_comm_dst = comm_dfs(df_src, df_dst, ppm, shift)\n",
    "    df_only_src = df_src.drop(df_comm_src.index)\n",
    "    df_only_dst = df_dst.drop(df_comm_dst.index)\n",
    "    return df_only_src, df_only_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_salts(df_sample, salts=[21.9819, 37.9558, 34.9694, 27.9949, 56.92]):\n",
    "    \"\"\" remove salts from dataframe df_sample, returns df and df_salts\n",
    "    \"\"\"\n",
    "    if df_sample.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    df = df_sample.copy()\n",
    "    df_salts = list()\n",
    "    for salt in salts:\n",
    "        df_salt = match_dfs(df, df, shift=salt)\n",
    "        df_salts.append(df_salt)\n",
    "    df_salts = pd.concat(df_salts).drop_duplicates()\n",
    "    df = df.drop(df_salts.index)\n",
    "    return df, df_salts\n",
    "\n",
    "def combinated_salts(limit=35, salts=[21.9819, 37.9558]):\n",
    "    \"\"\"return all the combinations of salts\n",
    "    \"\"\"\n",
    "    from itertools import product, filterfalse\n",
    "    \n",
    "    def filter_product(i):\n",
    "#         count = len([item for item in i if item <= 1])\n",
    "#         cond1 = i[2]>2 or i[0]>4 or i[1] > 4 or sum(i[:2])<i[2]\n",
    "        cond1 = len([item for item in i if item>0])>2\n",
    "        cond2 = sum(i) > limit\n",
    "        return any([cond1, cond2])\n",
    "    \n",
    "    possibilities = product(range(limit+1), repeat=len(salts))\n",
    "    possibilities_restricted = filterfalse(filter_product, possibilities)\n",
    "    \n",
    "    merge_salts = list()\n",
    "    for possibility in possibilities_restricted:\n",
    "        salt = np.dot(possibility, salts)\n",
    "        merge_salts.append(salt)\n",
    "    \n",
    "#     merge_salts = [item for item in merge_salts if item > 0]\n",
    "    return merge_salts\n",
    "\n",
    "\n",
    "def combinated_salts_v2(limit=35, salts=[21.9819, 37.9558]):\n",
    "    \"\"\"return all the combinations of salts\n",
    "    \"\"\"\n",
    "    from itertools import product, filterfalse\n",
    "    \n",
    "    def filter_product(i):\n",
    "#         count = len([item for item in i if item <= 1])\n",
    "#         cond1 = i[2]>2 or i[0]>4 or i[1] > 4 or sum(i[:2])<i[2]\n",
    "        cond1 = len([item for item in i if item>0])>3\n",
    "        cond2 = sum(i) > limit\n",
    "        return any([cond1, cond2])\n",
    "    \n",
    "    possibilities = product(range(limit+1), repeat=len(salts))\n",
    "    possibilities_restricted = filterfalse(filter_product, possibilities)\n",
    "    \n",
    "    merge_salts = list()\n",
    "    for possibility in possibilities_restricted:\n",
    "        salt = np.dot(possibility, salts)\n",
    "        merge_salts.append((salt, possibility))\n",
    "    \n",
    "#     merge_salts = [item for item in merge_salts if item > 0]\n",
    "    return merge_salts\n",
    "    \n",
    "def remove_combinated_salts(df_sample, limit=35, salts=[21.9819, 37.9558]):\n",
    "    \"\"\"remove salts combinations, returns df and df_salts\n",
    "    \"\"\"\n",
    "    merge_salts = combinated_salts(limit, salts)\n",
    "    return remove_salts(df_sample, merge_salts)\n",
    "\n",
    "# Na 21.9819, K 37.9558, Cl 35.9694, FA 46.0060, CO 27.9949, H2O 18.0106\n",
    "# NaCl 57.9513, KCl 73.9252  , 57.9513, 73.9252\n",
    "def detect_combined_salts(df, mass, limit=10, ppm=10, salts=[], amino=0):\n",
    "    \"\"\"detect salts(combined or not) from df, return a DataFrame contains salts\n",
    "    \"\"\"\n",
    "    if not salts:\n",
    "        salts = [21.9819, 37.9558]\n",
    "        salt_names = ['Na', 'K', 'NaCl', 'KCl']\n",
    "    merge_salts_v2 = combinated_salts_v2(limit, salts)\n",
    "#     merge_salts = [i[0] for i in merge_salts_v2l]\n",
    "    merge_salts_v2.sort(key=lambda i:i[0], reverse=False)\n",
    "#     merge_salts.sort(reverse=True)\n",
    "    \n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df_target = pd.DataFrame(columns=['Mass', 'RT', 'Vol'], index=[1])\n",
    "    df_target['Mass'] = mass\n",
    "    \n",
    "    df_salts = list()\n",
    "    for salt, composit in merge_salts_v2:\n",
    "        df_salt = match_dfs(df_target, df, shift=salt, ppm=ppm)\n",
    "        if not df_salt.empty:\n",
    "            df_salt['AdductsMass'] = salt\n",
    "            composition = ''\n",
    "            for idx, i in enumerate(composit):\n",
    "                if i > 0:\n",
    "                    composition += f'{i}{salt_names[idx]} '\n",
    "            df_salt['composit'] = composition\n",
    "            df_salts.append(df_salt)\n",
    "    if not df_salts:\n",
    "        print('df_salts empty')\n",
    "        return pd.DataFrame(columns=['Mass', 'RT', 'Vol'])\n",
    "    df_salts = pd.concat(df_salts).drop_duplicates()\n",
    "    \n",
    "    if amino > 0:\n",
    "        rounded_mass = int(mass- amino + 18.0106)\n",
    "    else:\n",
    "        rounded_mass = int(mass)\n",
    "    col = '{}'.format(rounded_mass)\n",
    "    col_composit = '{}_composition'.format(rounded_mass)\n",
    "    df.loc[df_salts.index, col] = abs(1E6 * (df_salts.Mass - df_salts.AdductsMass - mass)) / mass\n",
    "    df.loc[df_salts.index, col_composit] = df_salts.composit\n",
    "    return df_salts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_top(df_src, win=320, step=100, top=3):\n",
    "    \"\"\"Using a sliding window to find the top dots.\n",
    "    Param win: Window size, default 320 Da.\n",
    "    Param step: step size, default 100 Da.\n",
    "    Param top: the number of dots, those have the top Volumes of the window\n",
    "    \"\"\"\n",
    "#     df_chosen = list()\n",
    "#     low, high = df_src.Mass.min(), df_src.Mass.max()\n",
    "#     if high - low < step:\n",
    "#         return pd.DataFrame()\n",
    "    \n",
    "#     cur = low\n",
    "#     while high - cur > step:\n",
    "#         cur += step\n",
    "#         df = df_src[(df_src.Mass>=cur)&(df_src.Mass<cur+win)]\n",
    "#         df_top = df.sort_values('Vol', ascending=False).iloc[:top]\n",
    "#         df_chosen.append(df_top)\n",
    "    \n",
    "#     df_chosen = pd.concat(df_chosen).drop_duplicates()\n",
    "#     return df_chosen\n",
    "    return local_top_range(df_src, win, step, range=(0, top))\n",
    "\n",
    "def local_top_range(df_src, win=320, step=100, range=(0,3)):\n",
    "    \"\"\"Using a sliding window to find the top dots.\n",
    "    Param win: Window size, default 320 Da.\n",
    "    Param step: step size, default 100 Da.\n",
    "    Param range: the range of dots, those have the top Volumes of the window\n",
    "    \"\"\"\n",
    "    df_chosen = list()\n",
    "    low, high = df_src.Mass.min(), df_src.Mass.max()\n",
    "    if high - low < step:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    cur = low\n",
    "    while high - cur > step:\n",
    "        cur += step\n",
    "        df = df_src[(df_src.Mass>=cur)&(df_src.Mass<cur+win)]\n",
    "        df_top = df.sort_values('Vol', ascending=False).iloc[range[0]:range[1]]\n",
    "        df_chosen.append(df_top)\n",
    "    \n",
    "    df_chosen = pd.concat(df_chosen).drop_duplicates()\n",
    "    return df_chosen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
