{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/utils.ipynb\n",
    "%run ../modules/cds.ipynb\n",
    "%run ../modules/preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_N_1.xlsx'\n",
    "# df1 = pd.read_excel(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_N_2.xlsx'\n",
    "# df2 = pd.read_excel(fpath)\n",
    "# df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_M1_1.xlsx'\n",
    "# df6 = pd.read_excel(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_M2_2.xlsx'\n",
    "# df7 = pd.read_excel(fpath)\n",
    "# df6.shape, df7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_NAD_1.xlsx'\n",
    "# df3 = pd.read_excel(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_NAD_2.xlsx'\n",
    "# df4 = pd.read_excel(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA NAD_3.xlsx'\n",
    "# df5 = pd.read_excel(fpath)\n",
    "# df3.shape, df4.shape, df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_MAD_1.xlsx'\n",
    "# df8 = pd.read_excel(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA_MAD_2.xlsx'\n",
    "# df9 = pd.read_excel(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/deconvoluted/100nt RNA MAD_3.xlsx'\n",
    "# df10 = pd.read_excel(fpath)\n",
    "# df8.shape, df9.shape, df10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_cols = {\n",
    "#     'Monoisotopic Mass (mean)': 'Mass', \n",
    "#     'Sum Intensity (mean)': 'Vol',\n",
    "#     'Apex RT (mean)': 'RT'\n",
    "# }\n",
    "# df6 = df6.rename(columns=mean_cols)[['Mass', 'RT', 'Vol']]\n",
    "# reg_cols = {\n",
    "#     'Monoisotopic Mass': 'Mass', \n",
    "#     'Sum Intensity': 'Vol',\n",
    "#     'Apex RT': 'RT'\n",
    "# }\n",
    "\n",
    "# df1 = df1.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df2 = df2.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df3 = df3.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df4 = df4.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df5 = df5.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df7 = df7.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df8 = df8.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df9 = df9.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df10 = df10.rename(columns=reg_cols)[['Mass', 'RT', 'Vol']]\n",
    "# df1.shape, df2.shape, df6.shape, df7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/xyuan/Documents/Datasets/20220708/9_M_Nonm_50_50_ADneg.xlsx'\n",
    "df9 = load_data(fpath)\n",
    "fpath = '/Users/xyuan/Documents/Datasets/20220708/10_M_Nonm_70_30_ADneg.xlsx'\n",
    "df10 = load_data(fpath)\n",
    "df9.shape, df10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/xyuan/Downloads/7_M_Nonm_10_90_ADneg_yue_params.xlsx'\n",
    "dft = load_data(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = '/Users/xyuan/Downloads/3_M_Nonm_50_50_neg.xlsx'\n",
    "# df3 = load_data(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/1_M_Nonm_10_90_neg_rt_0.2.xlsx'\n",
    "# df1 = load_data(fpath)\n",
    "# fpath = '/Users/xyuan/Downloads/100nt_M_Non-m_10_90_AD_0.006.xlsx'\n",
    "fpath = '/Users/xyuan/Documents/Datasets/20220708/7_M_Nonm_10_90_ADneg_rt_0.2.xlsx'\n",
    "df71 = load_data(fpath)\n",
    "fpath = '/Users/xyuan/Documents/Datasets/20220708/7_M_Nonm_10_90_ADneg_rt_0.006.xlsx'\n",
    "df72 = load_data(fpath)\n",
    "fpath = '/Users/xyuan/Downloads/100nt_M_Non-m_10_90_AD_0.006.xlsx'\n",
    "df73 = load_data(fpath)\n",
    "df71.shape, df72.shape, df73.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = match_dfs(df71, df73)\n",
    "dfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly_zone(df71)\n",
    "# plotly_zone(df72)\n",
    "# plotly_zone(df73)\n",
    "\n",
    "plotly_zone(df9)\n",
    "plotly_zone(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly_zone(df[df.Mass>24000], y='Vol')\n",
    "df_top = local_top(df71)\n",
    "plotly_zone(df_top)\n",
    "bcr = base_calling_random(df_top)\n",
    "plotly_basecalling(*bcr)\n",
    "df_top = local_top(df72)\n",
    "plotly_zone(df_top)\n",
    "bcr = base_calling_random(df_top)\n",
    "plotly_basecalling(*bcr)\n",
    "# df1_30k = df1[df1.Mass>30000]\n",
    "# df3_30k = df3[df3.Mass>30000]\n",
    "# plotly_zone(df1_30k, y='Vol')\n",
    "# plotly_zone(df3_30k, y='Vol')\n",
    "# plotly_zone(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/xyuan/Downloads/100nt_modified_AD.xlsx'\n",
    "df = load_data(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove adducts from df_glu1\n",
    "adducts = [K, Na]\n",
    "dfm_adducts_list = list()\n",
    "for adduct in adducts:\n",
    "    dfm_r = match_dfs(df, df, shift=adduct)\n",
    "    dfm_adducts_list.append(dfm_r)\n",
    "df_adducts = pd.concat(dfm_adducts_list).drop_duplicates()\n",
    "df_without_adducts = df.drop(df_adducts.index)\n",
    "print(df.shape[0], df_without_adducts.shape[0], df_adducts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 1662 #2350\n",
    "dft = df[(df.Mass>target)&(df.Mass<target+1)]\n",
    "df_24k = df[(df.Mass>30000)&(df.Mass<34000)]\n",
    "# df_top = local_top(df)\n",
    "plotly_zone(df_24k, y='Vol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = '/Users/xyuan/Downloads/100nt_modified_result.xlsx'\n",
    "# df_100 = pd.read_excel(fpath)\n",
    "# seq = ''.join(df_100.Base2.tolist())\n",
    "# seq\n",
    "fpath = '~/Studio/tools/rna_100nt_5p.xlsx'\n",
    "df_100_5p = pd.read_excel(fpath)\n",
    "fpath = '~/Studio/tools/rna_100nt_3p.xlsx'\n",
    "df_100_3p = pd.read_excel(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_100_3p.head()\n",
    "# 443.0243 - 345.0475\n",
    "df_100_5p.Mass -= 79.9662\n",
    "df_100_5p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1648.2246 + M\n",
    "# # 443.0243 - 345.0475 - H2O\n",
    "df_ngs.shape\n",
    "# plotly_zone(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngs = df_100_5p.copy()\n",
    "df_sample = df_top.copy()\n",
    "\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "ShiftHit = namedtuple('ShiftHit', 'shift hit')\n",
    "\n",
    "def func(df_s1, df_s2, shift):\n",
    "    dfm = match_dfs(df_s1, df_s2, shift=shift)\n",
    "    sh = ShiftHit(shift=shift, hit=dfm.shape[0])\n",
    "    return sh\n",
    "\n",
    "PROCESSES = 8\n",
    "# params = [(df_ngs, df_wild_sample, shift) for shift in np.arange(0, 160, 1)]\n",
    "params = [(df_ngs, df_sample, shift) for shift in np.arange(-160, 160, 1)]\n",
    "with multiprocessing.Pool(PROCESSES) as pool:\n",
    "    shift_hits = pool.starmap(func, params)\n",
    "\n",
    "df_shift_hits = pd.DataFrame(shift_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_shift_hits[df_shift_hits.hit<df_shift_hits.shape[0]], x='shift', y='hit', labels={'shift': 'Mass Shift', 'hit': 'Hit Count'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sh_top = df_shift_hits[df_shift_hits.hit>1]\n",
    "shifts = df_sh_top['shift']\n",
    "df_sh_top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = [10, 9.9, 10.1,\n",
    "          14, 13.9, 14.1,\n",
    "         28, 27.9, 28.1,\n",
    "         42, 41.9, 42.1,\n",
    "         50, 49.9, 50.1]\n",
    "shifts = [10, 14, 28, 42, 50]\n",
    "# shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out data points which can generate base calling\n",
    "def func(df_s1, df_s2, shift):\n",
    "#     _, df = peer_dfs(df_s1, df_s2, shift=shift, ppm=100)\n",
    "    dfm = match_dfs(df_s1, df_s2, shift=shift, ppm=30)\n",
    "    \n",
    "#     bcr = base_calling_random(dfm, base_only=True)\n",
    "#     dfm = bcr[0].copy()\n",
    "    dfm['Shift'] = shift\n",
    "    return dfm\n",
    "\n",
    "PROCESSES = 8\n",
    "# params = [(df_ngs, df_wild, shift) for shift in shifts]\n",
    "params = [(df_ngs, df, shift) for shift in shifts]\n",
    "with multiprocessing.Pool(PROCESSES) as pool:\n",
    "    df_basecallings = pool.starmap(func, params)\n",
    "\n",
    "df_hits = pd.concat(df_basecallings).drop_duplicates()\n",
    "df_hits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_zone(df_hits, y='Shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_zone(df_hits, y='Shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-dance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "ShiftHit = namedtuple('ShiftHit', 'shift hit')\n",
    "\n",
    "def func(df_s1, df_s2, shift):\n",
    "    dfm = match_dfs(df_s1, df_s2, shift=shift)\n",
    "    sh = ShiftHit(shift=shift, hit=dfm.shape[0])\n",
    "    return sh\n",
    "\n",
    "# find out data points which can generate base calling\n",
    "def func2(df_s1, df_s2, shift):\n",
    "    _, df = peer_dfs(df_s1, df_s2, shift=shift)\n",
    "\n",
    "    bcr = base_calling_random(df, base_only=True)\n",
    "    df = bcr[0].copy()\n",
    "    df['Shift'] = shift\n",
    "    return df\n",
    "\n",
    "def process(dfs, df_ngs, shift_range, delta, full_mass):\n",
    "    \"\"\"ShiftSum\n",
    "    :param dfs: a set consists of two LC-MS datasets\n",
    "    :param df_ngs: a set contains two opposite mass ladders of an NGS sequence,\n",
    "    the first item is the mass ladder of 5´, the second is of 3´\n",
    "    :param shift_range: iterate the shift in between\n",
    "    \"\"\"\n",
    "    # 1\n",
    "    print('step 1')\n",
    "    PROCESSES = 8\n",
    "    params = [(df_ngs[0], dfs[0], shift) for shift in shift_range]\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        shift_hits = pool.starmap(func, params)\n",
    "    df_shift_hits_5p = pd.DataFrame(shift_hits)\n",
    "    \n",
    "    params = [(df_ngs[1], dfs[1], shift) for shift in shift_range]\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        shift_hits = pool.starmap(func, params)\n",
    "    df_shift_hits_3p = pd.DataFrame(shift_hits)\n",
    "    \n",
    "    # 2\n",
    "    print('step 2')\n",
    "    df_sh_top_5p = df_shift_hits_5p[df_shift_hits_5p.hit>1]\n",
    "    shifts_5p = df_sh_top_5p['shift']\n",
    "    \n",
    "    df_sh_top_3p = df_shift_hits_3p[df_shift_hits_3p.hit>1]\n",
    "    shifts_3p = df_sh_top_3p['shift']\n",
    "    \n",
    "    # 3\n",
    "    print('step 3')\n",
    "    pairs = list()\n",
    "    for i in shifts_5p:\n",
    "        for j in shifts_3p:\n",
    "            if i+j == delta: #144:\n",
    "                pairs.append((i, j))\n",
    "#                 print(i, j, '\\n')\n",
    "    \n",
    "    # 4\n",
    "    print('step 4')\n",
    "    PROCESSES = 8\n",
    "#     params = [(df_ngs, df_sample, shift) for shift in shifts]\n",
    "#     params = [(df_ngs[0], dfs[0], pair[0]) for pair in pairs]\n",
    "    params = [(df_ngs[0], dfs[0], shift) for shift in shifts_5p]\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        df_basecallings = pool.starmap(func2, params)\n",
    "    df_hits_5p = pd.concat(df_basecallings).drop_duplicates()\n",
    "    shift_5p = df_hits_5p.Shift.unique()\n",
    "    plotly_zone(df_hits_5p, y='Shift')\n",
    "    \n",
    "#     params = [(df_ngs[1], dfs[1], pair[1]) for pair in pairs]\n",
    "    params = [(df_ngs[1], dfs[1], shift) for shift in shifts_3p]\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        df_basecallings = pool.starmap(func2, params)\n",
    "    df_hits_3p = pd.concat(df_basecallings).drop_duplicates()\n",
    "    shift_3p = df_hits_3p.Shift.unique()\n",
    "    plotly_zone(df_hits_3p, y='Shift')\n",
    "#     return\n",
    "    # 5\n",
    "    print('step 5')\n",
    "    pairs = list()\n",
    "    # pairs_75nt = list()\n",
    "    for i in shift_5p:\n",
    "        for j in shift_3p:\n",
    "            if i+j == 42:\n",
    "                dft = df_hits_5p[df_hits_5p.Shift == i]\n",
    "                mass_5p = dft.sort_values('Mass')['Mass']\n",
    "                dft = df_hits_3p[df_hits_3p.Shift == j]\n",
    "                mass_3p = dft.sort_values('Mass')['Mass']\n",
    "                max_5p, max_3p = mass_5p.max(), mass_3p.max()\n",
    "                min_5p, min_3p = mass_5p.min(), mass_3p.min()\n",
    "                if min_5p + min_3p > full_mass or max_5p + max_3p < full_mass:\n",
    "                    continue\n",
    "                pairs.append((i, j))\n",
    "                print(i, j, '\\n', mass_5p.to_list(), '\\n', mass_3p.to_list())\n",
    "    \n",
    "    selected_5p = [i[0] for i in pairs]\n",
    "    selected_3p = [i[1] for i in pairs]\n",
    "    \n",
    "    # 6\n",
    "    print('step 6')\n",
    "    target_shifts = selected_5p.copy()\n",
    "    dft_5p = df_hits_5p[df_hits_5p.Shift.isin(target_shifts)]\n",
    "#     plotly_zone(dft_5p, y='Shift')\n",
    "    target_shifts = selected_3p.copy()\n",
    "    dft_3p = df_hits_3p[df_hits_3p.Shift.isin(target_shifts)]\n",
    "#     plotly_zone(dft_3p, y='Shift')\n",
    "    return dft_5p, dft_3p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = (df, df)\n",
    "df_ngs = (df_100_5p, df_100_3p)\n",
    "shift_range = np.arange(-160, 160, 1)\n",
    "delta = 11\n",
    "fullmass = 32327.3\n",
    "dfts_76 = process(dfs, df_ngs, shift_range, delta, fullmass)\n",
    "# dfts_76[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfts_76[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
